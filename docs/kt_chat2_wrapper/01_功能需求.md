# KTMoEWrapper SFT 集成功能需求

## 1. 功能背景与目标

### 1.1 现状问题

当前 LLaMA-Factory-KT 中的 KT SFT 微调功能（`kt_moe.py`）存在以下问题：

| 问题 | 描述 |
|------|------|
| **代码耦合** | 直接调用 `kt_kernel_ext.moe.MOESFTConfig` 和 `AMXBF16_SFT_MOE` 等 C++ 绑定 |
| **维护困难** | CPUInfer 单例、WorkerPoolConfig 手动管理，代码分散 |
| **TP 配置分散** | TP/no-TP 模式的配置逻辑分布在多处代码中 |
| **扩展性差** | 添加新量化方法需要修改多处代码 |
| **与上游同步困难** | kt-kernel 更新时需要大量代码修改 |

### 1.2 目标

引入 `KTMoEWrapper` 统一工厂接口，实现：

1. **统一入口**：推理和 SFT 使用相同的工厂接口
2. **简化使用**：无需了解 C++ 绑定细节
3. **自动管理**：CPUInfer 单例自动管理
4. **TP 透明**：通过单一参数控制 TP/no-TP 模式
5. **易于扩展**：kt-kernel 更新时只需升级依赖

---

## 2. 功能需求描述

### 2.1 统一接口需求

**需求 FR-001**：提供统一的 `KTMoEWrapper` 工厂接口

```python
# 推理模式
wrapper = KTMoEWrapper(..., mode="inference", method="AMXINT4")

# SFT 微调模式
wrapper = KTMoEWrapper(..., mode="sft", method="AMXBF16_SFT")
```

**验收标准**：
- 通过 `mode` 参数区分推理和 SFT 模式
- 通过 `method` 参数选择具体后端实现
- 返回相应的 Wrapper 实例

### 2.2 简化使用需求

**需求 FR-002**：封装 C++ 绑定细节

| 功能 | 现状 | 目标 |
|------|------|------|
| CPUInfer 初始化 | 手动创建 WorkerPoolConfig 和 CPUInfer | 自动单例管理 |
| 权重加载 | 直接调用 C++ task | Wrapper 方法封装 |
| 前向传播 | 手动提交 task 并同步 | `forward_sft()` 方法 |
| 反向传播 | 手动管理梯度缓冲区 | `backward()` 方法 |
| LoRA 同步 | 手动更新指针 | `update_lora_weights()` 方法 |

**验收标准**：
- 用户无需直接操作 `kt_kernel_ext` 模块
- 所有操作通过 Wrapper 方法完成

### 2.3 TP/no-TP 透明支持

**需求 FR-003**：通过 `threadpool_count` 参数统一控制 TP 模式

```python
# no-TP 模式（单 NUMA 节点）
wrapper = KTMoEWrapper(..., threadpool_count=1)

# TP 模式（多 NUMA 节点并行）
wrapper = KTMoEWrapper(..., threadpool_count=4)
```

**验收标准**：
- `threadpool_count=1` 启用 no-TP 模式
- `threadpool_count>1` 启用 TP 模式，自动分配 NUMA 子池
- C++ 层自动处理权重分割和计算调度
- Python 层完全透明，无需修改业务逻辑

### 2.4 SFT 核心方法需求

**需求 FR-004**：提供完整的 SFT 训练接口

| 方法 | 功能 | 签名 |
|------|------|------|
| `load_weights()` | 从预量化文件加载权重 | `(physical_to_logical_map) -> None` |
| `load_weights_from_tensors()` | 从张量加载权重 | `(gate_proj, up_proj, down_proj, ...) -> None` |
| `init_lora_weights()` | 初始化 6 个 LoRA 矩阵 | `(gate_lora_a, gate_lora_b, ...) -> None` |
| `forward_sft()` | SFT 前向传播 | `(hidden_states, expert_ids, weights, save_for_backward) -> Tensor` |
| `backward()` | 反向传播，计算梯度 | `(grad_output) -> (grad_input, grad_loras_dict)` |
| `update_lora_weights()` | 同步 LoRA 权重到 C++ | `() -> None` |

**验收标准**：
- 所有方法功能完整，可替代现有 `MOEAMXFunction` 和 `MOELayerWrapper`

---

## 3. 非功能需求

### 3.1 性能要求

**需求 NFR-001**：性能与直接调用 C++ 绑定一致

| 指标 | 要求 |
|------|------|
| 前向传播延迟 | 与现有实现差异 < 5% |
| 反向传播延迟 | 与现有实现差异 < 5% |
| 内存占用 | 与现有实现差异 < 10% |

### 3.2 兼容性要求

**需求 NFR-002**：支持现有 LoRA 配置

- 支持现有的 `lora_rank` 和 `lora_alpha` 配置
- 支持现有的 6 个 LoRA 矩阵格式
- 支持现有的 PyTorch autograd 集成方式

### 3.3 可扩展性要求

**需求 NFR-003**：易于适配 kt-kernel 的新功能

| 扩展类型 | 适配方式 |
|----------|---------|
| 新量化方法 | 在 `SFT_METHODS` frozenset 添加方法名，注册 C++ 类映射 |
| GPU experts | 通过 `num_gpu_experts` 参数启用（当前预留为 0） |
| 新配置参数 | 通过条件字段模式添加（如 K-Group 的 `group_size`） |

**验收标准**：
- 添加新 SFT 方法不需要修改 `KTMoEWrapper` 或 `BaseSFTMoEWrapper`
- kt-kernel 更新时，LLaMA-Factory-KT 只需升级依赖

---

## 4. 约束条件

### 4.1 依赖要求

| 依赖 | 版本要求 | 说明 |
|------|---------|------|
| kt-kernel | 支持 KTMoEWrapper 工厂接口 | 需包含 `experts.py`, `experts_sft.py` |
| PyTorch | >= 2.0 | BF16 支持 |
| Python | >= 3.9 | 类型提示支持 |

### 4.2 支持的模型架构

| 模型 | Router 类型 | 支持状态 |
|------|------------|---------|
| DeepSeek-V2/V3 | deepseek_gate | 支持 |
| Qwen2-MoE / Qwen3-MoE | linear | 支持 |
| Mixtral | linear | 支持 |

### 4.3 当前约束

| 约束 | 说明 | 未来计划 |
|------|------|---------|
| `num_gpu_experts=0` | Routed experts 全放 CPU | 预留接口，未来支持 GPU experts |
| TP 约束 | `intermediate_size % threadpool_count == 0` | C++ 层限制 |
| 同步执行 | SFT 模式不支持异步执行 | 需要保存激活值用于反向传播 |

### 4.4 支持的量化方法

**SFT 模式 (`mode="sft"`)**：

| 方法 | 说明 |
|------|------|
| `AMXBF16_SFT` | AMX BF16 精度训练（推荐） |
| `AMXINT8_SFT` | AMX INT8 量化训练 |
| `AMXINT4_SFT` | AMX INT4 量化训练 |
| `AMXINT4_1_SFT` | AMX INT4_1 量化训练 |
| `AMXINT4_KGroup_SFT` | AMX INT4 K-Group 量化训练 |
| `AMXINT4_1KGroup_SFT` | AMX INT4_1 K-Group 量化训练 |

---

## 5. 术语表

| 术语 | 定义 |
|------|------|
| **KTMoEWrapper** | kt-kernel 提供的 MoE 统一工厂接口 |
| **TP (Tensor Parallel)** | 张量并行，将 MoE 中间层按 NUMA 节点分割 |
| **no-TP** | 非张量并行，所有计算在单个 NUMA 节点 |
| **threadpool_count** | NUMA 子池数量，控制 TP/no-TP 模式 |
| **CPUInfer** | kt-kernel 的 CPU 推理引擎单例 |
| **BaseSFTMoEWrapper** | SFT MoE Wrapper 抽象基类 |
| **AMXSFTMoEWrapper** | AMX 加速的 SFT MoE Wrapper 具体实现 |
| **LoRA** | Low-Rank Adaptation，低秩自适应微调方法 |
